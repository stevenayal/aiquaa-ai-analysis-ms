"""
Microservicio de An√°lisis QA - Versi√≥n M√≠nima
FastAPI Service para an√°lisis automatizado de casos de prueba
"""

import os
from typing import List, Dict, Any, Optional
from datetime import datetime
from fastapi import FastAPI, HTTPException, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from fastapi.middleware.trustedhost import TrustedHostMiddleware
from pydantic import BaseModel, Field
from dotenv import load_dotenv

# Cargar variables de entorno
load_dotenv()

# Inicializar FastAPI
app = FastAPI(
    title="Microservicio de An√°lisis QA",
    description="""
    ## API de An√°lisis Automatizado de Casos de Prueba
    
    Esta API proporciona an√°lisis inteligente de contenido (casos de prueba, requerimientos, historias de usuario) utilizando IA generativa y t√©cnicas avanzadas de testing.
    
    ### Caracter√≠sticas:
    - ü§ñ An√°lisis automatizado con Google Gemini
    - üìä Observabilidad completa con Langfuse
    - üîó Integraci√≥n simplificada con Jira
    - üìù Generaci√≥n de casos de prueba estructurados
    - üéØ **NUEVO**: Generaci√≥n de casos con t√©cnicas avanzadas
    - üî¨ **NUEVO**: Aplicaci√≥n autom√°tica de t√©cnicas de dise√±o de pruebas
    - üìã **NUEVO**: Formato estructurado estandarizado
    - ‚ö° **OPTIMIZADO**: Endpoints unificados y par√°metros simplificados
    
    ### T√©cnicas Aplicadas Autom√°ticamente:
    - **Partici√≥n de Equivalencia**: Clases v√°lidas e inv√°lidas
    - **Valores L√≠mite**: Casos boundary y edge cases
    - **Casos de Uso**: Flujos principales y alternos
    - **Casos de Error**: Validaciones y manejo de errores
    - **Casos de Integraci√≥n**: Flujos end-to-end
    - **Casos de Seguridad**: Autenticaci√≥n y autorizaci√≥n
    
    ### Autenticaci√≥n:
    No se requiere autenticaci√≥n para las pruebas locales.
    
    ### Uso Simplificado:
    1. **An√°lisis unificado**: Usa `/analyze` para cualquier tipo de contenido
    2. **Integraci√≥n Jira**: Usa `/analyze-jira` para work items (solo ID requerido)
    3. **Generaci√≥n avanzada**: Usa `/generate-advanced-tests` para casos avanzados
    4. **Monitoreo**: Verifica el estado con `/health`
    
    ### Tipos de Contenido Soportados:
    - **test_case**: An√°lisis de casos de prueba existentes
    - **requirement**: An√°lisis de requerimientos
    - **user_story**: An√°lisis de historias de usuario
    """,
    version="1.0.0",
    docs_url="/docs",
    redoc_url="/redoc",
    openapi_url="/openapi.json",
    contact={
        "name": "Equipo de QA",
        "email": "qa-team@company.com",
    },
    license_info={
        "name": "MIT",
        "url": "https://opensource.org/licenses/MIT",
    },
    servers=[
        {
            "url": "https://ia-analisis-production.up.railway.app",
            "description": "Servidor de producci√≥n en Railway"
        },
        {
            "url": "http://localhost:8000",
            "description": "Servidor de desarrollo local"
        }
    ]
)

# Configurar CORS para Railway
app.add_middleware(
    CORSMiddleware,
    allow_origins=[
        "https://ia-analisis-production.up.railway.app",
        "http://localhost:8000",
        "http://localhost:3000",
        "http://127.0.0.1:8000",
        "http://127.0.0.1:3000"
    ],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Configurar TrustedHostMiddleware para Railway
app.add_middleware(
    TrustedHostMiddleware,
    allowed_hosts=[
        "ia-analisis-production.up.railway.app",
        "localhost",
        "127.0.0.1",
        "*.railway.app"
    ]
)

# Modelos Pydantic
class TestCase(BaseModel):
    """Caso de prueba generado con estructura estandarizada"""
    test_case_id: str = Field(..., description="ID del caso de prueba", example="CP-001-APLICACION-MODULO-DATO-CONDICION-RESULTADO")
    title: str = Field(..., description="T√≠tulo del caso de prueba en formato CP - 001 - Aplicacion - Modulo - Dato - Condicion - Resultado", example="CP - 001 - Aplicacion - Modulo - Dato - Condicion - Resultado")
    description: str = Field(..., description="Descripci√≥n detallada del caso de prueba")
    test_type: str = Field(..., description="Tipo de prueba", example="functional")
    priority: str = Field(..., description="Prioridad del caso de prueba", example="high")
    steps: List[str] = Field(..., description="Pasos detallados del caso de prueba")
    expected_result: str = Field(..., description="Resultado esperado en formato 'Resultado Esperado: [descripci√≥n]'", example="Resultado Esperado: Usuario autenticado exitosamente y redirigido al dashboard")
    preconditions: List[str] = Field(default_factory=list, description="Precondiciones en formato 'Precondicion: [descripci√≥n]'", example=["Precondicion: Usuario existe en la base de datos", "Precondicion: Sistema de autenticaci√≥n activo"])
    test_data: Optional[Dict[str, Any]] = Field(default_factory=dict, description="Datos de prueba espec√≠ficos")
    automation_potential: str = Field(..., description="Potencial de automatizaci√≥n", example="high")
    estimated_duration: str = Field(..., description="Duraci√≥n estimada", example="5-10 minutes")

class AnalysisRequest(BaseModel):
    """Solicitud unificada de an√°lisis de contenido para generar casos de prueba"""
    content_id: str = Field(..., description="ID √∫nico del contenido a analizar", example="TC-001", min_length=1, max_length=50)
    content: str = Field(..., description="Contenido a analizar (caso de prueba, requerimiento, historia de usuario)", example="Verificar que el usuario pueda iniciar sesi√≥n con credenciales v√°lidas", min_length=10, max_length=10000)
    content_type: str = Field("test_case", description="Tipo de contenido a analizar", example="test_case", pattern="^(test_case|requirement|user_story)$")
    analysis_level: Optional[str] = Field("medium", description="Nivel de an√°lisis y cobertura", example="high", pattern="^(low|medium|high|comprehensive)$")

class AnalysisResponse(BaseModel):
    """Respuesta unificada del an√°lisis de contenido"""
    content_id: str = Field(..., description="ID del contenido analizado", example="TC-001")
    analysis_id: str = Field(..., description="ID √∫nico del an√°lisis", example="analysis_TC001_1760825804")
    status: str = Field(..., description="Estado del an√°lisis", example="completed")
    test_cases: List[TestCase] = Field(default_factory=list, description="Lista de casos de prueba generados")
    confidence_score: float = Field(..., description="Puntuaci√≥n de confianza del an√°lisis (0-1)", example=0.85)
    processing_time: float = Field(..., description="Tiempo de procesamiento en segundos", example=8.81)
    created_at: datetime = Field(..., description="Timestamp de creaci√≥n del an√°lisis")

class AdvancedTestGenerationRequest(BaseModel):
    """Solicitud simplificada de generaci√≥n de casos de prueba avanzados"""
    requerimiento: str = Field(..., description="Requerimiento completo a analizar y generar casos de prueba", example="El sistema debe permitir a los usuarios autenticarse usando email y contrase√±a. El sistema debe validar las credenciales contra la base de datos y permitir el acceso solo a usuarios activos. En caso de credenciales incorrectas, debe mostrar un mensaje de error apropiado.", min_length=50, max_length=5000)
    aplicacion: str = Field(..., description="Nombre de la aplicaci√≥n o sistema", example="SISTEMA_AUTH", min_length=1, max_length=50)
    modulo: str = Field(..., description="M√≥dulo espec√≠fico del sistema que se va a probar", example="AUTENTICACION", min_length=1, max_length=50)
    servicio_publicado: Optional[str] = Field(None, description="URL o nombre del servicio publicado (si existe)", example="https://auth.sistema.com/login", max_length=200)

class AdvancedTestGenerationResponse(BaseModel):
    """Respuesta de la generaci√≥n de casos de prueba avanzados"""
    aplicacion: str = Field(..., description="Nombre de la aplicaci√≥n", example="SISTEMA_AUTH")
    generation_id: str = Field(..., description="ID √∫nico de la generaci√≥n", example="advanced_SISTEMA_AUTH_1760825804")
    status: str = Field(..., description="Estado de la generaci√≥n", example="completed")
    test_cases: List[TestCase] = Field(..., description="Lista de casos de prueba generados")
    coverage_analysis: Dict[str, Any] = Field(..., description="An√°lisis de cobertura de pruebas")
    confidence_score: float = Field(..., description="Puntuaci√≥n de confianza (0-1)", example=0.85)
    processing_time: float = Field(..., description="Tiempo de procesamiento en segundos", example=25.3)
    created_at: datetime = Field(..., description="Timestamp de creaci√≥n")

class HealthResponse(BaseModel):
    """Respuesta de salud del servicio"""
    status: str
    timestamp: datetime
    version: str
    components: Dict[str, str]

# Endpoint ra√≠z
@app.get("/", 
         summary="Informaci√≥n del servicio",
         description="Endpoint ra√≠z que proporciona informaci√≥n b√°sica sobre el microservicio de an√°lisis QA",
         tags=["Informaci√≥n"])
async def root():
    """Informaci√≥n del servicio"""
    return {
        "message": "Microservicio de An√°lisis QA",
        "version": "1.0.0",
        "docs": "/docs",
        "status": "running"
    }

# Health check
@app.get("/health", response_model=HealthResponse)
async def health_check():
    """Verificaci√≥n de salud del servicio"""
    return HealthResponse(
        status="healthy",
        timestamp=datetime.utcnow(),
        version="1.0.0",
        components={
            "api": "healthy",
            "database": "not_configured",
            "llm": "not_configured",
            "jira": "not_configured"
        }
    )

# Endpoint de an√°lisis (versi√≥n mock)
@app.post("/analyze", 
          response_model=AnalysisResponse,
          summary="Analizar contenido y generar casos de prueba",
          description="Analiza cualquier tipo de contenido (caso de prueba, requerimiento, historia de usuario) y genera casos de prueba usando IA",
          tags=["An√°lisis"])
async def analyze_content(request: AnalysisRequest):
    """An√°lisis de contenido (versi√≥n mock)"""
    start_time = datetime.utcnow()
    analysis_id = f"analysis_{request.content_id}_{int(start_time.timestamp())}"
    
    # Generar casos de prueba mock
    test_cases = [
        TestCase(
            test_case_id=f"CP-001-{request.content_id}-MODULO-DATO-CONDICION-RESULTADO",
            title=f"CP - 001 - {request.content_id} - MODULO - DATO - CONDICION - RESULTADO",
            description="Caso de prueba generado autom√°ticamente",
            test_type="functional",
            priority="high",
            steps=[
                "Paso 1: Preparar el entorno de prueba",
                "Paso 2: Ejecutar la acci√≥n principal",
                "Paso 3: Verificar el resultado"
            ],
            expected_result="Resultado Esperado: Operaci√≥n completada exitosamente",
            preconditions=["Precondicion: Sistema inicializado", "Precondicion: Datos de prueba disponibles"],
            test_data={"input": "datos de prueba"},
            automation_potential="high",
            estimated_duration="5-10 minutes"
        )
    ]
    
    processing_time = (datetime.utcnow() - start_time).total_seconds()
    
    return AnalysisResponse(
        content_id=request.content_id,
        analysis_id=analysis_id,
        status="completed",
        test_cases=test_cases,
        confidence_score=0.85,
        processing_time=processing_time,
        created_at=start_time
    )

# Endpoint de generaci√≥n avanzada (versi√≥n mock)
@app.post("/generate-advanced-tests", 
          response_model=AdvancedTestGenerationResponse,
          summary="Generar casos de prueba con t√©cnicas avanzadas",
          description="Genera casos de prueba aplicando t√©cnicas de dise√±o avanzadas de testing",
          tags=["Generaci√≥n Avanzada"])
async def generate_advanced_test_cases(request: AdvancedTestGenerationRequest):
    """Generaci√≥n de casos avanzados (versi√≥n mock)"""
    start_time = datetime.utcnow()
    generation_id = f"advanced_{request.aplicacion}_{int(start_time.timestamp())}"
    
    # Generar casos de prueba mock
    test_cases = []
    for i in range(1, 4):  # Generar 3 casos de prueba
        test_case_id = f"CP-{i:03d}-{request.aplicacion}-{request.modulo}-DATO-CONDICION-RESULTADO"
        title = f"CP - {i:03d} - {request.aplicacion} - {request.modulo} - DATO - CONDICION - RESULTADO"
        
        preconditions = ["Precondicion: Sistema inicializado", "Precondicion: Datos de prueba disponibles"]
        if request.servicio_publicado:
            preconditions.insert(0, f"Precondicion: Ingresar al publicado {request.servicio_publicado}")
        
        test_case = TestCase(
            test_case_id=test_case_id,
            title=title,
            description=f"Caso de prueba {i} generado para {request.aplicacion} - {request.modulo}",
            test_type="functional",
            priority="high",
            steps=[
                f"Paso 1: Preparar el entorno de prueba para {request.modulo}",
                f"Paso 2: Ejecutar la acci√≥n principal del caso {i}",
                f"Paso 3: Verificar el resultado esperado"
            ],
            expected_result=f"Resultado Esperado: Operaci√≥n {i} completada exitosamente en {request.modulo}",
            preconditions=preconditions,
            test_data={"aplicacion": request.aplicacion, "modulo": request.modulo},
            automation_potential="high",
            estimated_duration="5-10 minutes"
        )
        test_cases.append(test_case)
    
    processing_time = (datetime.utcnow() - start_time).total_seconds()
    
    return AdvancedTestGenerationResponse(
        aplicacion=request.aplicacion,
        generation_id=generation_id,
        status="completed",
        test_cases=test_cases,
        coverage_analysis={
            "functional_coverage": "90%",
            "edge_case_coverage": "75%",
            "integration_coverage": "80%"
        },
        confidence_score=0.85,
        processing_time=processing_time,
        created_at=start_time
    )

if __name__ == "__main__":
    import uvicorn
    
    try:
        port = int(os.getenv("PORT", 8000))
        log_level = os.getenv("LOG_LEVEL", "info").lower()
        is_production = os.getenv("RAILWAY_ENVIRONMENT") == "production"
        
        print(f"Starting Microservicio de An√°lisis QA - Port: {port}, Log Level: {log_level}, Production: {is_production}")
        
        uvicorn.run(
            "main_minimal:app",
            host="0.0.0.0",
            port=port,
            reload=not is_production,
            log_level=log_level,
            access_log=True
        )
    except Exception as e:
        print(f"Failed to start server: {e}")
        raise
